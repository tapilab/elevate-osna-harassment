{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See instructions here:\n",
    "\n",
    "https://github.com/tapilab/elevate-osna-starter/blob/master/lessons/week2/README.md#day-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@FlyGuyCree Nigga whatever one you gave me ü§¶üèª‚Äç‚ôÄÔ∏è</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArvindKejriwal . go to hell you ass hole.</td>\n",
       "      <td>hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@JohnJohnDaDon That ‚Äúnigga‚Äù done lost his fuck...</td>\n",
       "      <td>hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kane_tingle10 Can‚Äôt be fucked with them mate....</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@JHarris_TheDon Its honestly better anyways. T...</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0   @FlyGuyCree Nigga whatever one you gave me ü§¶üèª‚Äç‚ôÄÔ∏è  nonhostile\n",
       "1         @ArvindKejriwal . go to hell you ass hole.     hostile\n",
       "2  @JohnJohnDaDon That ‚Äúnigga‚Äù done lost his fuck...     hostile\n",
       "3  @kane_tingle10 Can‚Äôt be fucked with them mate....  nonhostile\n",
       "4  @JHarris_TheDon Its honestly better anyways. T...  nonhostile"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(datafile)[['text', 'hostile']]\n",
    "    df.columns = ['text', 'label']\n",
    "    df['label'] = ['hostile' if i==1 else 'nonhostile' for i in df.label]\n",
    "    return df\n",
    "\n",
    "df = load_data('~/Dropbox/elevate/harassment/training_data/data.csv.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hostile       3588\n",
       "nonhostile    3186\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    # just as an initial example, we will consider three\n",
    "    # word features in the model.\n",
    "    words_to_track = ['you', 'hate', 'love']\n",
    "    # will get different model for different features.\n",
    "    #words_to_track = ['you']\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        token_counts = Counter(re.sub('\\W+', ' ', row['text'].lower()).split())\n",
    "        for w in words_to_track:\n",
    "            features[w] = token_counts[w]\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec\n",
    "                \n",
    "X, vec = make_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6774x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1933 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6774, 21018)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, use CountVectorizer to create a term feature matrix.\n",
    "count_vec = CountVectorizer()\n",
    "X_words = count_vec.fit_transform(df.text)\n",
    "X_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21018 words\n",
      "99153 of 142375932 possible cells are non-zero (0.07%)\n"
     ]
    }
   ],
   "source": [
    "# how sparse is it? \n",
    "def print_sparsity(X_words):\n",
    "    print('%d words' % X_words.shape[1])\n",
    "    num_cells = X_words.shape[0] * X_words.shape[1]\n",
    "    print('%d of %d possible cells are non-zero (%.2f%%)' %\n",
    "          (X_words.nnz, num_cells,\n",
    "           100 * X_words.nnz/num_cells))\n",
    "print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_df=1\n",
      "21018 words\n",
      "99153 of 142375932 possible cells are non-zero (0.07%)\n",
      "\n",
      "\n",
      "min_df=2\n",
      "5120 words\n",
      "83255 of 34682880 possible cells are non-zero (0.24%)\n",
      "\n",
      "\n",
      "min_df=5\n",
      "1866 words\n",
      "74977 of 12640284 possible cells are non-zero (0.59%)\n",
      "\n",
      "\n",
      "min_df=10\n",
      "951 words\n",
      "69038 of 6442074 possible cells are non-zero (1.07%)\n"
     ]
    }
   ],
   "source": [
    "# how does sparsity vary with min_df?\n",
    "for min_df in [1,2,5,10]:\n",
    "    count_vec = CountVectorizer(min_df=min_df)\n",
    "    print('\\n\\nmin_df=%d' % min_df)\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 the\t2716\n",
      "                 you\t2622\n",
      "               nigga\t2340\n",
      "                  to\t1918\n",
      "                 and\t1691\n",
      "                that\t1641\n",
      "                  it\t1232\n",
      "                  is\t1221\n",
      "                shit\t1184\n",
      "                  of\t1091\n"
     ]
    }
   ],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ngram_range=(1, 1)\n",
      "5120 words\n",
      "83255 of 34682880 possible cells are non-zero (0.24%)\n",
      "                 the\t2716\n",
      "                 you\t2622\n",
      "               nigga\t2340\n",
      "                  to\t1918\n",
      "                 and\t1691\n",
      "                that\t1641\n",
      "                  it\t1232\n",
      "                  is\t1221\n",
      "                shit\t1184\n",
      "                  of\t1091\n",
      "\n",
      "ngram_range=(2, 2)\n",
      "9104 words\n",
      "41935 of 61670496 possible cells are non-zero (0.07%)\n",
      "            https co\t355\n",
      "              in the\t216\n",
      "              you re\t214\n",
      "          that nigga\t195\n",
      "            my nigga\t190\n",
      "          this nigga\t174\n",
      "               to be\t154\n",
      "            the fuck\t151\n",
      "              of the\t131\n",
      "           that shit\t120\n",
      "\n",
      "ngram_range=(3, 3)\n",
      "3080 words\n",
      "8252 of 20863920 possible cells are non-zero (0.04%)\n",
      "       what the fuck\t51\n",
      "      nigga https co\t28\n",
      "       piece of shit\t27\n",
      "         the fuck up\t26\n",
      "       shut the fuck\t23\n",
      "         the fuck is\t21\n",
      "        fuck off you\t19\n",
      "       is wrong with\t17\n",
      "     bitch ass nigga\t15\n",
      "       the fact that\t14\n",
      "\n",
      "ngram_range=(1, 3)\n",
      "17304 words\n",
      "133442 of 117217296 possible cells are non-zero (0.11%)\n",
      "                 the\t2716\n",
      "                 you\t2622\n",
      "               nigga\t2340\n",
      "                  to\t1918\n",
      "                 and\t1691\n",
      "                that\t1641\n",
      "                  it\t1232\n",
      "                  is\t1221\n",
      "                shit\t1184\n",
      "                  of\t1091\n"
     ]
    }
   ],
   "source": [
    "# top terms using different ngrams\n",
    "for ngram in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    count_vec = CountVectorizer(min_df=2, ngram_range=ngram)\n",
    "    print('\\nngram_range=%s' % str(ngram))\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)\n",
    "    print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'nonhostile': 3186, 'hostile': 3588})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 you\t             hostile\t1690\n",
      "                 you\t          nonhostile\t932\n",
      "                hate\t             hostile\t20\n",
      "                hate\t          nonhostile\t24\n",
      "                love\t             hostile\t44\n",
      "                love\t          nonhostile\t85\n"
     ]
    }
   ],
   "source": [
    "# how often does each word appear in each class?\n",
    "for word, idx in list(vec.vocabulary_.items())[:10]:\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "m2\n",
      "[[ 7  8]\n",
      " [ 9 10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1,  2,  3,  7,  8],\n",
       "        [ 4,  5,  6,  9, 10]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to combine two sparse matrices:\n",
    "from scipy.sparse import csr_matrix, hstack # \"horizontal stack\"\n",
    "m1 = csr_matrix([[1,2,3], [4,5,6]])\n",
    "print('m1')\n",
    "print(m1.todense())\n",
    "m2 = csr_matrix([[7,8], [9,10]])\n",
    "print('m2')\n",
    "print(m2.todense())\n",
    "hstack([m1, m2]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6774, 17307)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = hstack([X, X_words])\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "clf.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09542003,  0.52383939, -0.1823916 , ...,  0.42041654,\n",
       "         0.10496036, -0.10404671]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for binary classification, LogisticRegression stores a single coefficient vector\n",
    "clf.coef_\n",
    "# this would be a matrix for a multi-class probem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.09542003, -0.52383939,  0.1823916 , ..., -0.42041654,\n",
      "       -0.10496036,  0.10404671]), array([ 0.09542003,  0.52383939, -0.1823916 , ...,  0.42041654,\n",
      "        0.10496036, -0.10404671])]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = [-clf.coef_[0], clf.coef_[0]]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hostile', 'nonhostile'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all cross-validation folds: [0.5424354243542435, 0.5476014760147602, 0.5276752767527675, 0.5402214022140222, 0.5236336779911374]\n",
      "mean=0.54 std=0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train, test in kf.split(X):\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = clf.predict(X[test])\n",
    "    accuracies.append(accuracy_score(y[test], pred))\n",
    "    \n",
    "    \n",
    "print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
